{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3706eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b174e0",
   "metadata": {},
   "source": [
    "Idea, use the quantity to reformat the quantity into different common string representations of that float. Use those to find the bounds in the `input` string. Now let's write the functions\n",
    "\n",
    "- There's a problem with leading and trailing whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dcbfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = pd.read_csv('../data/nyt-ingredients-snapshot-2015.csv')\n",
    "ingredients.unit = ingredients.unit.str.strip()\n",
    "ingredients.name = ingredients.name.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe453b27",
   "metadata": {},
   "source": [
    "## Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce00e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pluralize(noun):\n",
    "    if re.search('[sxz]$', noun):\n",
    "         return re.sub('$', 'es', noun)\n",
    "    elif re.search('[^aeioudgkprt]h$', noun):\n",
    "        return re.sub('$', 'es', noun)\n",
    "    elif re.search('[aeiou]y$', noun):\n",
    "        return re.sub('y$', 'ies', noun)\n",
    "    else:\n",
    "        return noun + 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd3348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_to_string(decimal):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Don't love this\n",
    "    problem_fractions = {0.13: '1/8', 0.67: '2/3', 0.33: '1/3'}\n",
    "    if decimal in problem_fractions:\n",
    "        return problem_fractions.get(decimal)\n",
    "    \n",
    "    ratio = float(decimal).as_integer_ratio()\n",
    "    return '/'.join(str(d) for d in ratio)\n",
    "\n",
    "def string_to_decimal(string):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    numbers = string.split('/')\n",
    "    return float(numbers[0]) / float(numbers[1])\n",
    "    \n",
    "def _process_and_colloquial(string):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    measurements = {'third': '1/3', 'half': '1/2', 'quarter': '1/4', 'fourth': '1/4'}\n",
    "    splits = string.split(' and a ')\n",
    "    return float(splits[0]) + measurements.get(splits[1], '')\n",
    "    \n",
    "def _process_and(string):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splits = string.split(' and ')\n",
    "    return float(splits[0]) + string_to_decimal(splits[1])\n",
    "\n",
    "def _process(string):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splits = string.split(' ')\n",
    "    return float(splits[0]) + string_to_decimal(splits[1])\n",
    "\n",
    "def string_to_float(string):\n",
    "    \"\"\"\n",
    "    NOT GOOD NAMING\n",
    "    \"\"\"\n",
    "    patterns = ['\\d+\\s(and)\\s\\d\\/\\d', '\\d+\\s\\d\\/\\d']\n",
    "    pattern_dict = {'\\d+\\s(and)\\s\\d\\/\\d': _process_and, '\\d+\\s\\d\\/\\d': _process}\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        pt = re.compile(pattern)\n",
    "        match = re.search(pt, string)\n",
    "        if match:\n",
    "            return pattern_dict[pattern](match.group())\n",
    "        \n",
    "    return 0\n",
    "\n",
    "def reformat_string(string):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    patterns = ['\\d+\\s(and)\\s\\d\\/\\d', '\\d+\\s\\d\\/\\d', '\\d+\\/\\d+', '\\d+']\n",
    "    pattern_dict = {'\\d+\\s(and)\\s\\d\\/\\d': lambda x: float_to_string(_process_and(x)), \n",
    "                    '\\d+\\s\\d\\/\\d': lambda x: x,\n",
    "                    '\\d+\\/\\d+': lambda x: x,\n",
    "                    '\\d+': lambda x: x}\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        pt = re.compile(pattern)\n",
    "        match = re.search(pt, string)\n",
    "        if match:\n",
    "            return pattern_dict[pattern](match.group())\n",
    "        \n",
    "    return 0\n",
    "    \n",
    "            \n",
    "def float_to_string(value):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if value < 1:\n",
    "        if (value - int(value)) < 0.001:\n",
    "            return str(0)\n",
    "        \n",
    "        return decimal_to_string(value)\n",
    "    \n",
    "    if value == 1:\n",
    "        return str(1)\n",
    "    \n",
    "    else:\n",
    "        if (value - int(value)) < 0.001:\n",
    "            return str(int(value))\n",
    "        \n",
    "        return '{} {}'.format(str(int(value)), decimal_to_string(round(value - int(value), 2)))\n",
    "    \n",
    "named = {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', \n",
    "         6: 'six', 7: 'seven', 8: 'eight', 9: 'nine'}\n",
    "quarter = {0.25: 'quarter', 0.33: 'third', 0.5: 'half'}\n",
    "def float_to_regex(value, error_str='-1'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if value < 1:\n",
    "        if value < 0.001:\n",
    "            return [str(0)]\n",
    "        \n",
    "        return [decimal_to_string(value)]\n",
    "    \n",
    "    if value == 1:\n",
    "        return [str(1), 'one']\n",
    "    \n",
    "    else:\n",
    "        if (value - int(value)) < 0.001:\n",
    "            if value < 10:\n",
    "                return [str(int(value)), named[int(value)]]\n",
    "            \n",
    "            else:\n",
    "                return [str(int(value))]\n",
    "        \n",
    "        a = '{} {}'.format(str(int(value)), decimal_to_string(round(value - int(value), 2)))\n",
    "        b = '{} and {}'.format(str(int(value)), decimal_to_string(round(value - int(value), 2)))\n",
    "        c = '{} and a {}'.format(str(int(value)), quarter.get(round(value - int(value), 2), error_str))\n",
    "        return [a, b, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6461b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandata_debug_qty(ingredients):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, row in enumerate(ingredients.itertuples()):\n",
    "        entry = {'entities': []}\n",
    "        if pd.isna(row.input):\n",
    "            continue\n",
    "            \n",
    "        if not pd.isna(row.qty):\n",
    "            test = float_to_regex(row.qty)\n",
    "            matches = [re.search(t, row.input) for t in test]\n",
    "            if any(matches):\n",
    "                qty = next(match for match in matches if match is not None)\n",
    "                entry['entities'].append((*qty.span(), 'QUANTITY'))\n",
    "\n",
    "    \n",
    "        data.append((row.input, entry))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3f1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleandata_debug_qty(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c99780",
   "metadata": {},
   "source": [
    "## Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc04397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandata_debug_unit(ingredients):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, row in enumerate(ingredients.itertuples()):\n",
    "        entry = {'entities': []}\n",
    "        if pd.isna(row.input):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            if not pd.isna(row.unit):\n",
    "                unit = re.search(row.unit, row.input, re.IGNORECASE)\n",
    "                entry['entities'].append((*unit.span(), 'UNIT'))\n",
    "                \n",
    "                data.append((row.input, entry))\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd1e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleandata_debug_unit(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b13c5",
   "metadata": {},
   "source": [
    "## Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10dec283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandata_debug_name(ingredients):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    rows = []\n",
    "    for i, row in enumerate(ingredients.itertuples()):\n",
    "        entry = {'entities': []}\n",
    "        if pd.isna(row.input):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            if not pd.isna(row.name):\n",
    "                product = re.search(row.name, row.input, re.IGNORECASE)\n",
    "                if product:\n",
    "                    entry['entities'].append((*product.span(), 'PRODUCT'))\n",
    "        except Exception as e:\n",
    "            rows.append((i, e, row))\n",
    "                \n",
    "        data.append((row.input, entry))\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b8db2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleandata_debug_name(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abafb7a6",
   "metadata": {},
   "source": [
    "# Bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d2bd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is horrendous\n",
    "def cleandata(ingredients):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i, row in enumerate(ingredients.itertuples()):\n",
    "        entry = {'entities': []}\n",
    "        if pd.isna(row.input):\n",
    "            continue\n",
    "            \n",
    "        # Quantity\n",
    "        if not pd.isna(row.qty):\n",
    "            test = float_to_regex(row.qty)\n",
    "            matches = [re.search(t, row.input) for t in test]\n",
    "            if any(matches):\n",
    "                qty = next(match for match in matches if match is not None)\n",
    "                entry['entities'].append((*qty.span(), 'QUANTITY'))\n",
    "         \n",
    "        # Product\n",
    "        try:\n",
    "            if not pd.isna(row.name):\n",
    "                product = re.search(row.name, row.input, re.IGNORECASE)\n",
    "                if product:\n",
    "                    entry['entities'].append((*product.span(), 'PRODUCT'))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Unit\n",
    "        try:\n",
    "            if not pd.isna(row.unit):\n",
    "                unit = re.search(row.unit, row.input, re.IGNORECASE)\n",
    "                entry['entities'].append((*unit.span(), 'UNIT'))\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    \n",
    "        data.append((row.input, entry))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "396918e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacleaned = cleandata(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a1d406",
   "metadata": {},
   "source": [
    "## Overlapping String Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a38b037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please rewrite this this is so embarassing\n",
    "def overlap(data):\n",
    "    store = []\n",
    "    for i, row in enumerate(data):\n",
    "        pairs = row[1]['entities']\n",
    "        for p1 in pairs:\n",
    "            for p2 in pairs:\n",
    "                if p1 == p2:\n",
    "                    continue\n",
    "\n",
    "                condition_a = (p1[0] > p2[0] and p1[1] < p2[1])\n",
    "                condition_b = (p1[0] <= p2[0] and p1[1] >= p2[0])\n",
    "                condition_c = (p1[0] == p2[0] or p1[1] == p2[1])\n",
    "                if condition_a or condition_b or condition_c:\n",
    "                    store.append(i)\n",
    "                    \n",
    "    return list(set(store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3c2dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = overlap(datacleaned)\n",
    "DATA = [datacleaned[i] for i in range(len(datacleaned)) if i not in dupes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29f5c6",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38d24749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy.training.example import Example\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d105560",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "176c2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "daa1876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e56f5db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8950it [46:03,  3.24it/s]                           \n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = DATA[:int(len(DATA) * 0.5)]\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "stores = []\n",
    "losses = {}\n",
    "for batch in tqdm.tqdm(minibatch(TRAINING_DATA, size=BATCH_SIZE), total=len(TRAINING_DATA) // BATCH_SIZE):\n",
    "    for text, annotations in batch:\n",
    "        # create Example\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        # Update the model\n",
    "        nlp.update([example], losses=losses, drop=0.3)\n",
    "        \n",
    "    stores.append(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c9ebe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 teaspoon dried thyme\n",
      "Entities [('1/4', 'QUANTITY'), ('teaspoon', 'UNIT'), ('thyme', 'PRODUCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(DATA[19000][0])\n",
    "print (DATA[19000][0])\n",
    "print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34162abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 pounds kabocha or butternut squash, peeled and cut in small dice (about 3 cups peeled and diced, weighing 1 1/2 to 1 3/4 pounds), or 1 large acorn squash, cut in half \\n\\n(If using acorn squash, place in a 425 degree oven for 20 minutes before cutting in \n",
      "Entities [('2', 'QUANTITY'), ('kabocha', 'PRODUCT'), ('squash', 'PRODUCT'), ('squash', 'PRODUCT')]\n"
     ]
    }
   ],
   "source": [
    "string = ingredients.loc[ingredients.input.str.len() == ingredients.input.str.len().max()].input.iloc[0]\n",
    "doc = nlp(string)\n",
    "print (string)\n",
    "print('Entities', [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d72e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /Users/tyler/Projects/recipe-parser/recipe-parser/ingredient_parser/models\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/Users/tyler/Projects/recipe-parser/recipe-parser/ingredient_parser/models/'\n",
    "\n",
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
